{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "artist_siamese.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "_1Iw6CmWfffS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "3a206ea3-1295-40a7-8617-6793fe8c9cde"
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wlQqBl4Uhg4x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_loc9lUbhjRr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('drive/nnfl/NNFL/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pwHr28_UhllD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "03510a49-7914-4ff5-fd58-7fe703f2fd0e"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aleksey_Savrasov      Frida_Kahlo\t   resnet50.h5\r\n",
            "artist_siamese.ipynb  Michelangelo\t   resnet50.ipynb\r\n",
            "Claude_Monet\t      Pablo_Picasso\t   Salvador_Dali\r\n",
            "code\t\t      Paul_Cezanne\t   siam_resnet.h5\r\n",
            "data.h5\t\t      Pierre_Renoir\t   tranfer_resnet.h5\r\n",
            "data_x.h5\t      preprocessing.ipynb  transfer_resnet50.ipynb\r\n",
            "data_x.pickle\t      Rembrandt\t\t   Van_Gogh\r\n",
            "Da_Vinci\t      resnet50+dropout.h5  Wassily_Kandisky\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BzpayWMshrCx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa39c892-0987-478e-fd99-0e644fff2ad7"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,Dropout, Reshape,Concatenate\n",
        "from keras.models import Model, load_model,Sequential"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "9UMNZCzKhxBz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "resnet = keras.applications.resnet50.ResNet50(include_top=False, weights='imagenet' ,input_shape=(224,224,3))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gxEdfvtC5Ly3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for layer in resnet.layers:\n",
        "  layer.trainable = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ff4X3qzPh9ER",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Resnet+tranfer from imagenet+siamese"
      ]
    },
    {
      "metadata": {
        "id": "MnsNg0CPh3OR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "2e6fd406-29e2-4b76-f5ea-b6597573a43b"
      },
      "cell_type": "code",
      "source": [
        "X_in_1 = Input(shape=(224,224,3))\n",
        "X_in_2 = Input(shape=(224,224,3))\n",
        "X_in_3 = Input(shape=(224,224,3))\n",
        "\n",
        "X1 = resnet(X_in_1)\n",
        "X2 = resnet(X_in_2)\n",
        "X3 = resnet(X_in_3)\n",
        "#X = Dense(12,activation='softmax')(X)\n",
        "X = Concatenate(axis=1)([X1,X2,X3])\n",
        "model = Model(inputs=[X_in_1,X_in_2,X_in_3],outputs=X)\n",
        "model.summary()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_10 (InputLayer)           (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_11 (InputLayer)           (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "resnet50 (Model)                (None, 1, 1, 2048)   23587712    input_9[0][0]                    \n",
            "                                                                 input_10[0][0]                   \n",
            "                                                                 input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 3, 1, 2048)   0           resnet50[1][0]                   \n",
            "                                                                 resnet50[2][0]                   \n",
            "                                                                 resnet50[3][0]                   \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8hLT73f8HoMy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ee2qmzyNjpCJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
        "    \"\"\"\n",
        "    Implementation of the triplet loss as defined by formula (3)\n",
        "    \n",
        "    Arguments:\n",
        "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
        "    y_pred -- python list containing three objects:\n",
        "            anchor -- the encodings for the anchor images, of shape (None, 128)\n",
        "            positive -- the encodings for the positive images, of shape (None, 128)\n",
        "            negative -- the encodings for the negative images, of shape (None, 128)\n",
        "    \n",
        "    Returns:\n",
        "    loss -- real number, value of the loss\n",
        "    \"\"\"\n",
        "    \n",
        "    anchor, positive, negative = y_pred[:,0,:], y_pred[:,1,:], y_pred[:,2,:]\n",
        "    \n",
        "    ### START CODE HERE ### (≈ 4 lines)\n",
        "    # Step 1: Compute the (encoding) distance between the anchor and the positive\n",
        "    pos_dist = tf.reduce_sum(tf.square(anchor - positive))\n",
        "    # Step 2: Compute the (encoding) distance between the anchor and the negative\n",
        "    neg_dist = tf.reduce_sum(tf.square(anchor - negative))\n",
        "    # Step 3: subtract the two previous distances and add alpha.\n",
        "    basic_loss = pos_dist - neg_dist + alpha\n",
        "    # Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples.\n",
        "    loss = tf.maximum(basic_loss, 0)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ha7ajH6lj0rT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss=triplet_loss,metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iV5kSo4jj7Pj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "hf=h5py.File('data_x.h5','r')\n",
        "x = hf.get('dataset_1')\n",
        "y = hf.get('dataset_2')\n",
        "\n",
        "x = np.asarray(x)\n",
        "y = np.asarray(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Ea0vtLMcQ09",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YCt5a2G3tQiu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4447
        },
        "outputId": "68b206a8-072b-47d0-df38-1a70cba45baf"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "path = os.listdir('.')\n",
        "path.sort(key=str)\n",
        "fold = path[:12]\n",
        "#print(fold)\n",
        "\n",
        "for j in range(100):\n",
        "  X1 = []\n",
        "  X2 = []\n",
        "  X3 = []\n",
        "  for i in range(50):\n",
        "      a,b = random.sample(range(len(fold)),2)\n",
        "      fold1 = os.listdir(fold[a])\n",
        "      fold1.sort(key=str.lower)\n",
        "      fold2 = os.listdir(fold[b])\n",
        "      fold2.sort(key=str.lower)\n",
        "      #print(len(fold1))\n",
        "      c,d = random.sample(range(0,len(fold1[:-1])),2)\n",
        "      e = np.random.randint(0,len(fold2[:-1]))\n",
        "      #print(c==d)\n",
        "      img1 = np.asarray(cv2.imread(fold[a]+'/'+fold1[c],1))\n",
        "      ran = np.random.randint(0,100)\n",
        "      img1 = img1[ran:ran+224,ran:ran+224] \n",
        "      img2 = np.asarray(cv2.imread(fold[a]+'/'+fold1[d],1))\n",
        "      ran = np.random.randint(0,100)\n",
        "      img2 = img2[ran:ran+224,ran:ran+224]\n",
        "      img3 = np.asarray(cv2.imread(fold[b]+'/'+fold2[e],1))\n",
        "      ran = np.random.randint(0,100)\n",
        "      img3 = img3[ran:ran+224,ran:ran+224]\n",
        "      #print(img1.shape,img2.shape,img3.shape)\n",
        "      #print(img1.all() == img2.all())\n",
        "      if(len(img1.shape) == 3 and len(img2.shape) == 3 and len(img3.shape) == 3):\n",
        "        X1.append(img1)\n",
        "        X2.append(img2)  \n",
        "        X3.append(img3)\n",
        "        \n",
        "  X1 = np.asarray(X1)\n",
        "  print(X1.shape)\n",
        "  X2 = np.asarray(X2)\n",
        "  X3 = np.asarray(X3)\n",
        "  y = np.zeros((X1.shape[0],3,1,2048))\n",
        "  print(y.shape)\n",
        "  model.fit([X1,X2,X3],y,epochs=5,batch_size=8)\n",
        "  resnet.save('siam_resnet.h5')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50, 224, 224, 3)\n",
            "(50, 3, 1, 2048)\n",
            "Epoch 1/5\n",
            "50/50 [==============================] - 7s 134ms/step - loss: 155.2262 - acc: 0.0000e+00\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 7s 130ms/step - loss: 137.5706 - acc: 0.0000e+00\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 7s 131ms/step - loss: 1821.9678 - acc: 0.0000e+00\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 3352.9157 - acc: 0.0000e+00\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 7s 130ms/step - loss: 834.3945 - acc: 0.0000e+00\n",
            "(50, 224, 224, 3)\n",
            "(50, 3, 1, 2048)\n",
            "Epoch 1/5\n",
            "50/50 [==============================] - 7s 134ms/step - loss: 114.6438 - acc: 0.0000e+00\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 7s 130ms/step - loss: 161.7793 - acc: 0.0000e+00\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 7s 131ms/step - loss: 85.0573 - acc: 0.0000e+00\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 7s 131ms/step - loss: 34.3434 - acc: 0.0000e+00\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
            "(50, 224, 224, 3)\n",
            "(50, 3, 1, 2048)\n",
            "Epoch 1/5\n",
            "50/50 [==============================] - 7s 136ms/step - loss: 71.2153 - acc: 0.0000e+00\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 11.7148 - acc: 0.0000e+00\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 7s 130ms/step - loss: 25.8029 - acc: 0.0067\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 7s 132ms/step - loss: 9.7968 - acc: 0.0000e+00\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 6.2694 - acc: 0.0000e+00\n",
            "(50, 224, 224, 3)\n",
            "(50, 3, 1, 2048)\n",
            "Epoch 1/5\n",
            "50/50 [==============================] - 7s 134ms/step - loss: 6.5059 - acc: 0.0067\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 4.5724 - acc: 0.0000e+00\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 7s 132ms/step - loss: 14.5637 - acc: 0.0000e+00\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 13.0009 - acc: 0.0000e+00\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 7s 130ms/step - loss: 6.4614 - acc: 0.0000e+00\n",
            "(50, 224, 224, 3)\n",
            "(50, 3, 1, 2048)\n",
            "Epoch 1/5\n",
            "50/50 [==============================] - 7s 135ms/step - loss: 3.5932 - acc: 0.0067\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 0.4367 - acc: 0.0000e+00\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 1.6833 - acc: 0.0000e+00\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 7s 133ms/step - loss: 2.2234 - acc: 0.0067\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 1.8146 - acc: 0.0000e+00\n",
            "(50, 224, 224, 3)\n",
            "(50, 3, 1, 2048)\n",
            "Epoch 1/5\n",
            "50/50 [==============================] - 7s 135ms/step - loss: 2.2041 - acc: 0.0000e+00\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 2.7244 - acc: 0.0000e+00\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 7s 130ms/step - loss: 1.6436 - acc: 0.0000e+00\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 7s 133ms/step - loss: 1.1107 - acc: 0.0067\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 0.7328 - acc: 0.0000e+00\n",
            "(50, 224, 224, 3)\n",
            "(50, 3, 1, 2048)\n",
            "Epoch 1/5\n",
            "50/50 [==============================] - 7s 134ms/step - loss: 2.9885 - acc: 0.0000e+00\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 7s 130ms/step - loss: 1.2961 - acc: 0.0000e+00\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 7s 132ms/step - loss: 1.5631 - acc: 0.0000e+00\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 6s 129ms/step - loss: 0.3148 - acc: 0.0000e+00\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 1.5198 - acc: 0.0000e+00\n",
            "(50, 224, 224, 3)\n",
            "(50, 3, 1, 2048)\n",
            "Epoch 1/5\n",
            "50/50 [==============================] - 7s 134ms/step - loss: 0.7162 - acc: 0.0000e+00\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 7s 132ms/step - loss: 1.9788 - acc: 0.0000e+00\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 1.0754 - acc: 0.0000e+00\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 0.5009 - acc: 0.0000e+00\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 7s 132ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
            "(50, 224, 224, 3)\n",
            "(50, 3, 1, 2048)\n",
            "Epoch 1/5\n",
            "50/50 [==============================] - 7s 136ms/step - loss: 1.5857 - acc: 0.0000e+00\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 7s 130ms/step - loss: 1.7522 - acc: 0.0000e+00\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 1.1778 - acc: 0.0000e+00\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 7s 132ms/step - loss: 1.0889 - acc: 0.0000e+00\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 1.3649 - acc: 0.0000e+00\n",
            "(50, 224, 224, 3)\n",
            "(50, 3, 1, 2048)\n",
            "Epoch 1/5\n",
            "50/50 [==============================] - 7s 133ms/step - loss: 0.4051 - acc: 0.0000e+00\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 7s 131ms/step - loss: 0.8441 - acc: 0.0000e+00\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 7s 131ms/step - loss: 0.8185 - acc: 0.0000e+00\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 0.7220 - acc: 0.0000e+00\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 7s 130ms/step - loss: 0.6405 - acc: 0.0000e+00\n",
            "(50, 224, 224, 3)\n",
            "(50, 3, 1, 2048)\n",
            "Epoch 1/5\n",
            "50/50 [==============================] - 7s 133ms/step - loss: 0.8004 - acc: 0.0000e+00\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 7s 132ms/step - loss: 0.5603 - acc: 0.0000e+00\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 0.3117 - acc: 0.0000e+00\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 0.4998 - acc: 0.0000e+00\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 7s 132ms/step - loss: 0.5260 - acc: 0.0000e+00\n",
            "(50, 224, 224, 3)\n",
            "(50, 3, 1, 2048)\n",
            "Epoch 1/5\n",
            "50/50 [==============================] - 7s 134ms/step - loss: 0.6736 - acc: 0.0000e+00\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 0.0811 - acc: 0.0000e+00\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 7s 132ms/step - loss: 0.1599 - acc: 0.0000e+00\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 0.2134 - acc: 0.0000e+00\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 7s 130ms/step - loss: 0.2400 - acc: 0.0000e+00\n",
            "(50, 224, 224, 3)\n",
            "(50, 3, 1, 2048)\n",
            "Epoch 1/5\n",
            "50/50 [==============================] - 7s 133ms/step - loss: 0.7577 - acc: 0.0000e+00\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 7s 132ms/step - loss: 0.1843 - acc: 0.0000e+00\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 0.5672 - acc: 0.0000e+00\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 7s 130ms/step - loss: 0.0921 - acc: 0.0000e+00\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 7s 132ms/step - loss: 0.1607 - acc: 0.0000e+00\n",
            "(50, 224, 224, 3)\n",
            "(50, 3, 1, 2048)\n",
            "Epoch 1/5\n",
            "50/50 [==============================] - 7s 134ms/step - loss: 0.3145 - acc: 0.0000e+00\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 0.6593 - acc: 0.0067\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 7s 131ms/step - loss: 0.2542 - acc: 0.0000e+00\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 7s 131ms/step - loss: 0.5194 - acc: 0.0000e+00\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 0.4249 - acc: 0.0067\n",
            "(50, 224, 224, 3)\n",
            "(50, 3, 1, 2048)\n",
            "Epoch 1/5\n",
            "50/50 [==============================] - 7s 136ms/step - loss: 0.2295 - acc: 0.0000e+00\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 0.4680 - acc: 0.0067\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 0.3345 - acc: 0.0000e+00\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 7s 132ms/step - loss: 0.2532 - acc: 0.0000e+00\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 7s 130ms/step - loss: 0.1935 - acc: 0.0000e+00\n",
            "(50, 224, 224, 3)\n",
            "(50, 3, 1, 2048)\n",
            "Epoch 1/5\n",
            "50/50 [==============================] - 7s 134ms/step - loss: 0.1711 - acc: 0.0067\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 7s 131ms/step - loss: 0.1742 - acc: 0.0067\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 7s 131ms/step - loss: 0.1703 - acc: 0.0200\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 0.3009 - acc: 0.0000e+00\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 7s 131ms/step - loss: 0.1601 - acc: 0.0133\n",
            "(50, 224, 224, 3)\n",
            "(50, 3, 1, 2048)\n",
            "Epoch 1/5\n",
            "50/50 [==============================] - 7s 135ms/step - loss: 0.1721 - acc: 0.0067\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 0.1760 - acc: 0.0267\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 0.1813 - acc: 0.0133\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 7s 132ms/step - loss: 0.1658 - acc: 0.0267\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 7s 130ms/step - loss: 0.2591 - acc: 0.0267\n",
            "(50, 224, 224, 3)\n",
            "(50, 3, 1, 2048)\n",
            "Epoch 1/5\n",
            "50/50 [==============================] - 7s 134ms/step - loss: 0.2986 - acc: 0.0000e+00\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 6s 129ms/step - loss: 0.0033 - acc: 0.0000e+00\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 7s 131ms/step - loss: 0.0746 - acc: 0.0067\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 7s 131ms/step - loss: 0.1659 - acc: 0.0067\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 0.0477 - acc: 0.0000e+00\n",
            "(50, 224, 224, 3)\n",
            "(50, 3, 1, 2048)\n",
            "Epoch 1/5\n",
            "50/50 [==============================] - 7s 134ms/step - loss: 0.3529 - acc: 0.0000e+00\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 7s 131ms/step - loss: 0.1496 - acc: 0.0000e+00\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 6s 129ms/step - loss: 0.2493 - acc: 0.0067\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 0.2511 - acc: 0.0000e+00\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 7s 131ms/step - loss: 0.3919 - acc: 0.0067\n",
            "(50, 224, 224, 3)\n",
            "(50, 3, 1, 2048)\n",
            "Epoch 1/5\n",
            "50/50 [==============================] - 7s 135ms/step - loss: 0.2821 - acc: 0.0067\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 0.1066 - acc: 0.0000e+00\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 7s 130ms/step - loss: 0.4252 - acc: 0.0067\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 7s 131ms/step - loss: 0.1213 - acc: 0.0000e+00\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 6s 130ms/step - loss: 0.1302 - acc: 0.0067\n",
            "(50, 224, 224, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-62df64625f7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0mX1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0mX2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m   \u001b[0mX3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \"\"\"\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (224,224,3) into shape (224)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "q2ZqgTEeeWzU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Testing the resnet now"
      ]
    },
    {
      "metadata": {
        "id": "0AMJ03gqoNZS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p=np.random.permutation(x.shape[0])\n",
        "x = np.asarray(x)\n",
        "y = np.asarray(y)\n",
        "y = y.reshape((2997,12))\n",
        "x = x[p]\n",
        "y = y[p]\n",
        "\n",
        "x_train = x[:2698]\n",
        "y_train = y[:2698]\n",
        "x_test = x[2698:]\n",
        "y_test = y[2698:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TI6xhIwqfXS2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "2cd69362-c1f3-44d2-c9f7-484eb37120ed"
      },
      "cell_type": "code",
      "source": [
        "resnet = keras.models.load_model('siam_resnet.h5')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/models.py:282: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ef1bKKeOfomr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for layer in resnet.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IweFicHpflKV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "7dbbb7f5-3faa-4747-847e-8ad0cd026566"
      },
      "cell_type": "code",
      "source": [
        "X_in = Input(shape=(224,224,3))\n",
        "X = resnet(X_in)\n",
        "X = Flatten()(X)\n",
        "X = Dropout(0.5)(X)\n",
        "X = Dense(12,activation='softmax')(X)\n",
        "\n",
        "model = Model(inputs=X_in,outputs=X)\n",
        "model.summary()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "resnet50 (Model)             (None, 1, 1, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 12)                24588     \n",
            "=================================================================\n",
            "Total params: 23,612,300\n",
            "Trainable params: 24,588\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dE2A4-8Af4jF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "3acb28d9-eb7d-4ddd-f8cf-2a944225262d"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train,validation_data=(x_test,y_test), epochs = 15, batch_size = 64)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2698 samples, validate on 299 samples\n",
            "Epoch 1/15\n",
            "2698/2698 [==============================] - 26s 10ms/step - loss: 2.2815 - acc: 0.1872 - val_loss: 2.3714 - val_acc: 0.0702\n",
            "Epoch 2/15\n",
            "2698/2698 [==============================] - 26s 10ms/step - loss: 2.2806 - acc: 0.2027 - val_loss: 2.3711 - val_acc: 0.0702\n",
            "Epoch 3/15\n",
            "2698/2698 [==============================] - 26s 10ms/step - loss: 2.2819 - acc: 0.2016 - val_loss: 2.3709 - val_acc: 0.0702\n",
            "Epoch 4/15\n",
            "2698/2698 [==============================] - 26s 10ms/step - loss: 2.2750 - acc: 0.1972 - val_loss: 2.3702 - val_acc: 0.0702\n",
            "Epoch 5/15\n",
            "2698/2698 [==============================] - 26s 10ms/step - loss: 2.2710 - acc: 0.2057 - val_loss: 2.3700 - val_acc: 0.0702\n",
            "Epoch 6/15\n",
            "2698/2698 [==============================] - 26s 10ms/step - loss: 2.2758 - acc: 0.1994 - val_loss: 2.3699 - val_acc: 0.0702\n",
            "Epoch 7/15\n",
            "2698/2698 [==============================] - 26s 10ms/step - loss: 2.2706 - acc: 0.1953 - val_loss: 2.3695 - val_acc: 0.0702\n",
            "Epoch 8/15\n",
            "2698/2698 [==============================] - 26s 10ms/step - loss: 2.2653 - acc: 0.2113 - val_loss: 2.3692 - val_acc: 0.0702\n",
            "Epoch 9/15\n",
            "2698/2698 [==============================] - 26s 10ms/step - loss: 2.2607 - acc: 0.2050 - val_loss: 2.3690 - val_acc: 0.0702\n",
            "Epoch 10/15\n",
            "2698/2698 [==============================] - 26s 10ms/step - loss: 2.2713 - acc: 0.2050 - val_loss: 2.3686 - val_acc: 0.0702\n",
            "Epoch 11/15\n",
            "2698/2698 [==============================] - 26s 10ms/step - loss: 2.2585 - acc: 0.2146 - val_loss: 2.3685 - val_acc: 0.0702\n",
            "Epoch 12/15\n",
            "2698/2698 [==============================] - 26s 10ms/step - loss: 2.2636 - acc: 0.2053 - val_loss: 2.3683 - val_acc: 0.0702\n",
            "Epoch 13/15\n",
            "2698/2698 [==============================] - 26s 10ms/step - loss: 2.2604 - acc: 0.2046 - val_loss: 2.3682 - val_acc: 0.0702\n",
            "Epoch 14/15\n",
            "2698/2698 [==============================] - 26s 10ms/step - loss: 2.2672 - acc: 0.2087 - val_loss: 2.3679 - val_acc: 0.0702\n",
            "Epoch 15/15\n",
            "2698/2698 [==============================] - 26s 10ms/step - loss: 2.2693 - acc: 0.1994 - val_loss: 2.3678 - val_acc: 0.0702\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f90a4fab320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "QP0k_epTLOmY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('siam_resnet_with_softmax.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QCopNoyikx4N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "without dropout"
      ]
    },
    {
      "metadata": {
        "id": "q4V6wuo5f8kK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "1e6315d7-6685-4d05-edfb-e69dc7698a6a"
      },
      "cell_type": "code",
      "source": [
        " model.fit(x_train, y_train,validation_data=(x_test,y_test), epochs = 15, batch_size = 64)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2698 samples, validate on 299 samples\n",
            "Epoch 1/15\n",
            "2698/2698 [==============================] - 31s 12ms/step - loss: 2.4728 - acc: 0.1023 - val_loss: 2.4723 - val_acc: 0.1070\n",
            "Epoch 2/15\n",
            "2698/2698 [==============================] - 25s 9ms/step - loss: 2.4462 - acc: 0.1405 - val_loss: 2.4614 - val_acc: 0.1070\n",
            "Epoch 3/15\n",
            "2698/2698 [==============================] - 25s 9ms/step - loss: 2.4238 - acc: 0.1568 - val_loss: 2.4522 - val_acc: 0.1171\n",
            "Epoch 4/15\n",
            "2698/2698 [==============================] - 25s 9ms/step - loss: 2.4052 - acc: 0.1720 - val_loss: 2.4442 - val_acc: 0.1171\n",
            "Epoch 5/15\n",
            "2698/2698 [==============================] - 25s 9ms/step - loss: 2.3881 - acc: 0.2016 - val_loss: 2.4373 - val_acc: 0.1171\n",
            "Epoch 6/15\n",
            "2698/2698 [==============================] - 26s 9ms/step - loss: 2.3757 - acc: 0.1950 - val_loss: 2.4314 - val_acc: 0.1171\n",
            "Epoch 7/15\n",
            "2698/2698 [==============================] - 26s 9ms/step - loss: 2.3617 - acc: 0.2013 - val_loss: 2.4260 - val_acc: 0.1171\n",
            "Epoch 8/15\n",
            "2698/2698 [==============================] - 26s 9ms/step - loss: 2.3534 - acc: 0.2064 - val_loss: 2.4212 - val_acc: 0.1171\n",
            "Epoch 9/15\n",
            "2698/2698 [==============================] - 26s 9ms/step - loss: 2.3456 - acc: 0.2098 - val_loss: 2.4173 - val_acc: 0.1171\n",
            "Epoch 10/15\n",
            "2698/2698 [==============================] - 26s 9ms/step - loss: 2.3340 - acc: 0.2013 - val_loss: 2.4138 - val_acc: 0.1171\n",
            "Epoch 11/15\n",
            "2698/2698 [==============================] - 26s 9ms/step - loss: 2.3258 - acc: 0.2131 - val_loss: 2.4110 - val_acc: 0.1171\n",
            "Epoch 12/15\n",
            "2698/2698 [==============================] - 26s 9ms/step - loss: 2.3210 - acc: 0.2090 - val_loss: 2.4085 - val_acc: 0.1171\n",
            "Epoch 13/15\n",
            "2698/2698 [==============================] - 26s 9ms/step - loss: 2.3134 - acc: 0.2168 - val_loss: 2.4063 - val_acc: 0.1171\n",
            "Epoch 14/15\n",
            "2698/2698 [==============================] - 26s 9ms/step - loss: 2.3050 - acc: 0.2139 - val_loss: 2.4040 - val_acc: 0.1171\n",
            "Epoch 15/15\n",
            "2698/2698 [==============================] - 26s 9ms/step - loss: 2.3074 - acc: 0.2157 - val_loss: 2.4021 - val_acc: 0.1171\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f918b452c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "TDaUIHrikzv_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "e699bbb5-1c38-4e3b-ecc9-472ce9215b99"
      },
      "cell_type": "code",
      "source": [
        " model.fit(x_train, y_train,validation_data=(x_test,y_test), epochs = 15, batch_size = 64)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2698 samples, validate on 299 samples\n",
            "Epoch 1/15\n",
            "2698/2698 [==============================] - 26s 10ms/step - loss: 2.2479 - acc: 0.2394 - val_loss: 2.3779 - val_acc: 0.0702\n",
            "Epoch 2/15\n",
            "2698/2698 [==============================] - 25s 9ms/step - loss: 2.2499 - acc: 0.2328 - val_loss: 2.3784 - val_acc: 0.0702\n",
            "Epoch 3/15\n",
            "2698/2698 [==============================] - 26s 9ms/step - loss: 2.2405 - acc: 0.2450 - val_loss: 2.3786 - val_acc: 0.0702\n",
            "Epoch 4/15\n",
            "2698/2698 [==============================] - 25s 9ms/step - loss: 2.2371 - acc: 0.2457 - val_loss: 2.3790 - val_acc: 0.0702\n",
            "Epoch 5/15\n",
            "2698/2698 [==============================] - 25s 9ms/step - loss: 2.2351 - acc: 0.2446 - val_loss: 2.3796 - val_acc: 0.0702\n",
            "Epoch 6/15\n",
            "2698/2698 [==============================] - 25s 9ms/step - loss: 2.2310 - acc: 0.2417 - val_loss: 2.3799 - val_acc: 0.0702\n",
            "Epoch 7/15\n",
            "2698/2698 [==============================] - 25s 9ms/step - loss: 2.2335 - acc: 0.2487 - val_loss: 2.3796 - val_acc: 0.0702\n",
            "Epoch 8/15\n",
            "2698/2698 [==============================] - 25s 9ms/step - loss: 2.2327 - acc: 0.2420 - val_loss: 2.3799 - val_acc: 0.0702\n",
            "Epoch 9/15\n",
            "2698/2698 [==============================] - 25s 9ms/step - loss: 2.2266 - acc: 0.2398 - val_loss: 2.3804 - val_acc: 0.0702\n",
            "Epoch 10/15\n",
            "2698/2698 [==============================] - 25s 9ms/step - loss: 2.2284 - acc: 0.2413 - val_loss: 2.3807 - val_acc: 0.0702\n",
            "Epoch 11/15\n",
            "2698/2698 [==============================] - 25s 9ms/step - loss: 2.2214 - acc: 0.2431 - val_loss: 2.3811 - val_acc: 0.0702\n",
            "Epoch 12/15\n",
            "2698/2698 [==============================] - 25s 9ms/step - loss: 2.2179 - acc: 0.2443 - val_loss: 2.3813 - val_acc: 0.0702\n",
            "Epoch 13/15\n",
            "2698/2698 [==============================] - 25s 9ms/step - loss: 2.2159 - acc: 0.2394 - val_loss: 2.3819 - val_acc: 0.0702\n",
            "Epoch 14/15\n",
            "2698/2698 [==============================] - 25s 9ms/step - loss: 2.2178 - acc: 0.2450 - val_loss: 2.3826 - val_acc: 0.0702\n",
            "Epoch 15/15\n",
            "2698/2698 [==============================] - 25s 9ms/step - loss: 2.2123 - acc: 0.2443 - val_loss: 2.3826 - val_acc: 0.0702\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f917f84a860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "6onX28rqA1om",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}