{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "style_loss+siamese.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/jadevaibhav/ArtistIdentifier/blob/master/style_loss+siamese.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "4XVCI5_G7yaH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "387ac41b-d67a-4ee9-af3b-cac522ef012e"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,Dropout, Reshape,Concatenate\n",
        "from keras.models import Model, load_model,Sequential\n",
        "model = keras.applications.vgg16.VGG16(include_top=False, weights='imagenet',input_shape = (224,224,3))\n",
        "\n",
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uvytH8bRJVMx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "57abd281-3c4b-4e17-b430-889ba0b190fa"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KjKMAyuu9MRo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ErgSmTHU8AiS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "40a717be-4d89-4604-c4f2-93dc8ec02ff4"
      },
      "cell_type": "code",
      "source": [
        "#vgg.summary()\n",
        "for layer in model.layers:\n",
        "  if(layer.name in STYLE_LAYERS):\n",
        "    print(layer.name)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "block1_pool\n",
            "block2_pool\n",
            "block3_pool\n",
            "block4_pool\n",
            "block5_pool\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sTgoSdlvJLfP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "layer_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ngZPJogF9kaE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: compute_layer_style_cost\n",
        "\n",
        "def compute_layer_style_cost(a_S, a_G):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    a_S -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image S \n",
        "    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image G\n",
        "    \n",
        "    Returns: \n",
        "    J_style_layer -- tensor representing a scalar value, style cost defined above by equation (2)\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    # Retrieve dimensions from a_G (≈1 line)\n",
        "    (m,n_H, n_W, n_C) = a_G.get_shape().as_list()\n",
        "    #print(m,n_C,n_H)\n",
        "    #print(a_G.shape[1])\n",
        "    \n",
        "    #a_G = tf.convert_to_tensor(a_G)\n",
        "    #a_S = tf.convert_to_tensor(a_S)\n",
        "    \n",
        "    #print(tf.transpose(a_S,perm=[0,3,2,1]).shape)\n",
        "    \n",
        "    # Reshape the images to have them of shape (n_C, n_H*n_W) (≈2 lines)\n",
        "    a_S = Reshape((n_C,n_H*n_W))(keras.layers.Permute((3,2,1))(a_S))\n",
        "    a_G = Reshape((n_C,n_H*n_W))(keras.layers.Permute((3,2,1))(a_G))\n",
        "    \n",
        "    #print(a_S.shape)\n",
        "    # Computing gram_matrices for both images S and G (≈2 lines)\n",
        "    GS = gram_matrix(a_S)\n",
        "    GG = gram_matrix(a_G)\n",
        "    \n",
        "    # Computing the loss (≈1 line)\n",
        "    J_style_layer = tf.reduce_sum(tf.square(tf.subtract(GS,GG))/(4*(n_C**2)*((n_H*n_W)**2)))\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return J_style_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nu-onjMd9khO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: gram_matrix\n",
        "\n",
        "def gram_matrix(A):\n",
        "    \"\"\"\n",
        "    Argument:\n",
        "    A -- matrix of shape (n_C, n_H*n_W)\n",
        "    \n",
        "    Returns:\n",
        "    GA -- Gram matrix of A, of shape (n_C, n_C)\n",
        "    \"\"\"\n",
        "    ### START CODE HERE ### (≈1 line)\n",
        "    GA = keras.layers.Dot(0)([A,A])\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return GA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LkHxvCER8DFJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "STYLE_LAYERS = [\n",
        "    'block1_pool', \n",
        "    'block2_pool', \n",
        "    'block3_pool', \n",
        "    'block4_pool',\n",
        "    'block5_pool']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8Pg-9fSzFI9p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def multi_model(model):\n",
        "  \n",
        "  output = []\n",
        "  \n",
        "  for layer_name in STYLE_LAYERS:\n",
        "    \n",
        "    out = model.get_layer(layer_name).output\n",
        "    #print(type(out))\n",
        "    #out = Reshape((out.shape[1],out.shape[2],out.shape[3]))(out)\n",
        "    #print(type(out))\n",
        "    output.append(out) \n",
        "  #output = tf.convert_to_tensor(output)\n",
        "  m = Model(inputs= model.input ,outputs=output)\n",
        "  return m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cANch9_NQ2qm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def art_model(in_shape,model):\n",
        "  \n",
        "  mod = multi_model(model)\n",
        "  \n",
        "  in1 = Input(in_shape)\n",
        "  in2 = Input(in_shape)\n",
        "  #print(type(in1))\n",
        "  a_a = mod(in1)\n",
        "  a_s = mod(in2)\n",
        "  \n",
        "  #print(a_s[0].shape)\n",
        "  #print(a_s[0])\n",
        "  \n",
        "  out1 = Concatenate(axis = 1)([a_a[0],a_s[0]])\n",
        "  out2 = Concatenate(axis = 1)([a_a[1],a_s[1]])\n",
        "  out3 = Concatenate(axis = 1)([a_a[2],a_s[2]])\n",
        "  out4 = Concatenate(axis = 1)([a_a[3],a_s[3]])\n",
        "  out5 = Concatenate(axis = 1)([a_a[4],a_s[4]])\n",
        "  \n",
        "  #print(out1.shape)\n",
        "  m = Model(inputs = [in1,in2],outputs = [out1,out2,out3,out4,out5])\n",
        "  return m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zFXZFEvUTQNc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "def style_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Implementation of the triplet loss as defined by formula (3)\n",
        "    \n",
        "    Arguments:\n",
        "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
        "    y_pred -- python list containing three objects:\n",
        "            anchor -- the encodings for the anchor images, of shape (None, 128)\n",
        "            positive -- the encodings for the positive images, of shape (None, 128)\n",
        "            negative -- the encodings for the negative images, of shape (None, 128)\n",
        "    \n",
        "    Returns:\n",
        "    loss -- real number, value of the loss\n",
        "    \"\"\"\n",
        "    \n",
        "    #anchor, positive, negative = y_pred[:,0,:], y_pred[:,1,:], y_pred[:,2,:]\n",
        "    \n",
        "    #print(y_pred.shape)\n",
        "    shape = y_pred.shape\n",
        "    l = int(int(shape[1])*(0.5))\n",
        "    y1 = y_pred[:,0:l,:,:]\n",
        "    y2 = y_pred[:,l:,:,:]\n",
        "    #print(y1)    \n",
        "\n",
        "    J_style = compute_layer_style_cost(y1,y2)\n",
        "    \n",
        "    #for i in range(len(STYLE_LAYERS)):\n",
        "      \n",
        "      #cost = compute_layer_style_cost(y_pred[i,0,:,:],y_pred[i,1,:,:])\n",
        "      #J_style += cost\n",
        "   \n",
        "    \n",
        "    ### START CODE HERE ### (≈ 4 lines)\n",
        "    # Step 1: Compute the (encoding) distance between the anchor and the positive\n",
        "    #pos_dist = tf.reduce_sum(tf.square(anchor - positive))\n",
        "    # Step 2: Compute the (encoding) distance between the anchor and the negative\n",
        "    #neg_dist = tf.reduce_sum(tf.square(anchor - negative))\n",
        "    # Step 3: subtract the two previous distances and add alpha.\n",
        "    #basic_loss = pos_dist - neg_dist + alpha\n",
        "    # Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples.\n",
        "    #loss = tf.maximum(basic_loss, 0)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return J_style"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gFIhMPCsS009",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "1b95355f-8da5-4daa-c20c-b5a32de76637"
      },
      "cell_type": "code",
      "source": [
        "m = art_model((224,224,3),model)\n",
        "m.compile(optimizer= 'adam', loss = style_loss , metrics = None)\n",
        "m.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_1 (Model)                 [(None, 112, 112, 64 14714688    input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 224, 112, 64) 0           model_1[1][0]                    \n",
            "                                                                 model_1[2][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 112, 56, 128) 0           model_1[1][1]                    \n",
            "                                                                 model_1[2][1]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 56, 28, 256)  0           model_1[1][2]                    \n",
            "                                                                 model_1[2][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 28, 14, 512)  0           model_1[1][3]                    \n",
            "                                                                 model_1[2][3]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 14, 7, 512)   0           model_1[1][4]                    \n",
            "                                                                 model_1[2][4]                    \n",
            "==================================================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IPT31NzSyp3G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "to0LsCQYy-ME",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E2dzhAEWzE_4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2qgP48r5zzk6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('drive/nnfl/NNFL')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mdDJ2Ahu0AFG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "94edf4f4-0850-47b9-a8cb-7e190e351d16"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aleksey_Savrasov      Michelangelo\t   siam_resnet.h5\r\n",
            "artist_siamese.ipynb  Pablo_Picasso\t   siam_resnet_with_softmax.h5\r\n",
            "Claude_Monet\t      Paul_Cezanne\t   siam+style_vgg_art_model.h5\r\n",
            "code\t\t      Pierre_Renoir\t   style_loss+siamese.ipynb\r\n",
            "comparison.ipynb      preprocessing.ipynb  test.h5\r\n",
            "data.h5\t\t      Rembrandt\t\t   tranfer_resnet.h5\r\n",
            "data_x.h5\t      resnet50+dropout.h5  transfer_resnet50.ipynb\r\n",
            "data_x.pickle\t      resnet50.h5\t   Van_Gogh\r\n",
            "Da_Vinci\t      resnet50.ipynb\t   Wassily_Kandisky\r\n",
            "Frida_Kahlo\t      Salvador_Dali\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OkkWgyLMTq41",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2070
        },
        "outputId": "f7e7ae40-a24b-4869-c6fc-b6e26fab6019"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "path = os.listdir('.')\n",
        "path.sort(key=str)\n",
        "fold = path[:12]\n",
        "#print(fold)\n",
        "\n",
        "for j in range(100):\n",
        "  X1 = []\n",
        "  X2 = []\n",
        "  #X3 = []\n",
        "  for i in range(50):\n",
        "      a = np.random.randint(0,len(fold))\n",
        "      fold1 = os.listdir(fold[a])\n",
        "      fold1.sort(key=str.lower)\n",
        "      #fold2 = os.listdir(fold[b])\n",
        "      #fold2.sort(key=str.lower)\n",
        "      #print(len(fold1))\n",
        "      c,d = random.sample(range(0,len(fold1[:-1])),2)\n",
        "      #e = np.random.randint(0,len(fold2[:-1]))\n",
        "      #print(c==d)\n",
        "      img1 = np.asarray(cv2.imread(fold[a]+'/'+fold1[c],1))\n",
        "      ran = np.random.randint(0,100)\n",
        "      img1 = img1[ran:ran+224,ran:ran+224] \n",
        "      img2 = np.asarray(cv2.imread(fold[a]+'/'+fold1[d],1))\n",
        "      ran = np.random.randint(0,100)\n",
        "      img2 = img2[ran:ran+224,ran:ran+224]\n",
        "      #img3 = np.asarray(cv2.imread(fold[b]+'/'+fold2[e],1))\n",
        "      #ran = np.random.randint(0,100)\n",
        "      #img3 = img3[ran:ran+224,ran:ran+224]\n",
        "      #print(img1.shape,img2.shape,img3.shape)\n",
        "      #print(img1.all() == img2.all())\n",
        "      if(len(img1.shape) == 3 and len(img2.shape) == 3):\n",
        "        X1.append(img1)\n",
        "        X2.append(img2)  \n",
        "        #X3.append(img3)\n",
        "        \n",
        "  X1 = np.asarray(X1)\n",
        "  #print(X1.shape)\n",
        "  X2 = np.asarray(X2)\n",
        "  #X3 = np.asarray(X3)\n",
        "  \n",
        "  y1 = np.zeros((50, 112, 112, 64))\n",
        "  y2 = np.zeros((50, 56, 56, 128))\n",
        "  y3 = np.zeros((50, 28, 28, 256))\n",
        "  y4 = np.zeros((50, 14, 14, 512))\n",
        "  y5 = np.zeros((50, 7, 7, 512))\n",
        "  \n",
        "  y = [y1,y2,y3,y4,y5]\n",
        "  #print(y.shape)\n",
        "  m.fit([X1,X2],y,epochs=5,batch_size=4)\n",
        "  m.save('siam+style_vgg_art_model.h5')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "50/50 [==============================] - 25s 501ms/step - loss: 19011487744.9600 - concatenate_1_loss: 3822980093.4400 - concatenate_2_loss: 7673351469.0450 - concatenate_3_loss: 7511736194.5580 - concatenate_4_loss: 3419255.5637 - concatenate_5_loss: 206.5560\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 18s 370ms/step - loss: 1851470781.4400 - concatenate_1_loss: 1841390533.1200 - concatenate_2_loss: 10080275.7856 - concatenate_3_loss: 15.9021 - concatenate_4_loss: 3.5070e-07 - concatenate_5_loss: 1.2548e-07\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 18s 370ms/step - loss: 1377977564.1600 - concatenate_1_loss: 1376996685.4400 - concatenate_2_loss: 980876.9369 - concatenate_3_loss: 1.1067 - concatenate_4_loss: 2.8871e-07 - concatenate_5_loss: 5.2823e-08\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 18s 370ms/step - loss: 1075929428.4800 - concatenate_1_loss: 1075535198.7200 - concatenate_2_loss: 394237.7369 - concatenate_3_loss: 0.4680 - concatenate_4_loss: 8.5999e-08 - concatenate_5_loss: 2.4081e-08\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 19s 370ms/step - loss: 857834471.6800 - concatenate_1_loss: 857555592.9600 - concatenate_2_loss: 278889.8488 - concatenate_3_loss: 0.3499 - concatenate_4_loss: 2.9008e-08 - concatenate_5_loss: 1.1173e-08\n",
            "Epoch 1/5\n",
            "50/50 [==============================] - 19s 372ms/step - loss: 992446504.3200 - concatenate_1_loss: 991799474.5600 - concatenate_2_loss: 647016.6241 - concatenate_3_loss: 0.9170 - concatenate_4_loss: 4.0366e-08 - concatenate_5_loss: 9.0574e-09\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 18s 369ms/step - loss: 862080243.2000 - concatenate_1_loss: 861345809.9200 - concatenate_2_loss: 734447.3481 - concatenate_3_loss: 0.9963 - concatenate_4_loss: 2.1892e-08 - concatenate_5_loss: 6.5526e-09\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 18s 368ms/step - loss: 734368940.8000 - concatenate_1_loss: 733785432.9600 - concatenate_2_loss: 583500.0663 - concatenate_3_loss: 0.7790 - concatenate_4_loss: 1.1792e-08 - concatenate_5_loss: 5.8731e-09\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 18s 370ms/step - loss: 623940062.7200 - concatenate_1_loss: 623450232.9600 - concatenate_2_loss: 489833.6588 - concatenate_3_loss: 0.5713 - concatenate_4_loss: 6.7361e-09 - concatenate_5_loss: 5.6622e-09\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 19s 371ms/step - loss: 508625397.7600 - concatenate_1_loss: 508205543.6800 - concatenate_2_loss: 419857.1222 - concatenate_3_loss: 0.4808 - concatenate_4_loss: 5.2422e-09 - concatenate_5_loss: 5.2264e-09\n",
            "Epoch 1/5\n",
            "50/50 [==============================] - 18s 369ms/step - loss: 477088586.2400 - concatenate_1_loss: 476821775.0400 - concatenate_2_loss: 266802.3971 - concatenate_3_loss: 0.0781 - concatenate_4_loss: 1.7169e-11 - concatenate_5_loss: 6.6759e-10\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 18s 368ms/step - loss: 428812999.6800 - concatenate_1_loss: 428731776.0000 - concatenate_2_loss: 81224.0089 - concatenate_3_loss: 0.0630 - concatenate_4_loss: 5.6464e-12 - concatenate_5_loss: 1.2256e-10\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 18s 366ms/step - loss: 377000257.9200 - concatenate_1_loss: 376989128.9600 - concatenate_2_loss: 11129.8361 - concatenate_3_loss: 0.0149 - concatenate_4_loss: 3.9458e-11 - concatenate_5_loss: 9.3736e-11\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 18s 366ms/step - loss: 341599788.4800 - concatenate_1_loss: 341595785.2800 - concatenate_2_loss: 4004.1831 - concatenate_3_loss: 0.0065 - concatenate_4_loss: 1.4760e-11 - concatenate_5_loss: 8.2167e-11\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 18s 366ms/step - loss: 314630162.8800 - concatenate_1_loss: 314627347.3600 - concatenate_2_loss: 2812.3596 - concatenate_3_loss: 0.0043 - concatenate_4_loss: 6.6108e-12 - concatenate_5_loss: 6.3068e-11\n",
            "Epoch 1/5\n",
            "50/50 [==============================] - 18s 369ms/step - loss: 254933315.8400 - concatenate_1_loss: 254906895.3600 - concatenate_2_loss: 26419.2245 - concatenate_3_loss: 0.6302 - concatenate_4_loss: 1.9185e-09 - concatenate_5_loss: 7.4021e-11\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 18s 367ms/step - loss: 233954826.2400 - concatenate_1_loss: 233948534.7200 - concatenate_2_loss: 6289.4255 - concatenate_3_loss: 0.2047 - concatenate_4_loss: 3.2523e-10 - concatenate_5_loss: 3.0793e-10\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 18s 368ms/step - loss: 213688396.8000 - concatenate_1_loss: 213684676.8000 - concatenate_2_loss: 3722.1865 - concatenate_3_loss: 0.1390 - concatenate_4_loss: 1.7130e-10 - concatenate_5_loss: 3.9403e-10\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 19s 370ms/step - loss: 199716271.6800 - concatenate_1_loss: 199713938.2400 - concatenate_2_loss: 2334.1228 - concatenate_3_loss: 0.0915 - concatenate_4_loss: 8.8324e-11 - concatenate_5_loss: 4.3575e-10\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 19s 372ms/step - loss: 179467856.8000 - concatenate_1_loss: 179466406.0800 - concatenate_2_loss: 1450.2550 - concatenate_3_loss: 0.0588 - concatenate_4_loss: 4.1961e-11 - concatenate_5_loss: 4.2209e-10\n",
            "Epoch 1/5\n",
            "50/50 [==============================] - 19s 372ms/step - loss: 169164020.8000 - concatenate_1_loss: 169163936.9600 - concatenate_2_loss: 82.8201 - concatenate_3_loss: 5.0220e-04 - concatenate_4_loss: 4.0475e-17 - concatenate_5_loss: 2.8626e-13\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 19s 372ms/step - loss: 164276598.8800 - concatenate_1_loss: 164276517.2000 - concatenate_2_loss: 79.7456 - concatenate_3_loss: 4.7330e-04 - concatenate_4_loss: 2.5143e-17 - concatenate_5_loss: 1.8856e-13\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 19s 372ms/step - loss: 146030519.3600 - concatenate_1_loss: 146030441.6000 - concatenate_2_loss: 77.3118 - concatenate_3_loss: 4.4484e-04 - concatenate_4_loss: 2.0491e-17 - concatenate_5_loss: 1.6471e-13\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 19s 373ms/step - loss: 138866991.6800 - concatenate_1_loss: 138866913.6000 - concatenate_2_loss: 77.6684 - concatenate_3_loss: 4.2901e-04 - concatenate_4_loss: 1.5327e-17 - concatenate_5_loss: 1.3669e-13\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 19s 372ms/step - loss: 132367462.5600 - concatenate_1_loss: 132367383.6800 - concatenate_2_loss: 78.6190 - concatenate_3_loss: 4.2226e-04 - concatenate_4_loss: 1.1084e-17 - concatenate_5_loss: 1.1302e-13\n",
            "Epoch 1/5\n",
            "50/50 [==============================] - 18s 369ms/step - loss: 116884240.2800 - concatenate_1_loss: 116883693.6000 - concatenate_2_loss: 546.6773 - concatenate_3_loss: 9.8470e-04 - concatenate_4_loss: 1.1043e-15 - concatenate_5_loss: 1.7513e-12\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 18s 368ms/step - loss: 109257916.1600 - concatenate_1_loss: 109257464.9600 - concatenate_2_loss: 450.0973 - concatenate_3_loss: 7.6694e-04 - concatenate_4_loss: 1.9193e-15 - concatenate_5_loss: 3.0611e-12\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 18s 367ms/step - loss: 101848078.8800 - concatenate_1_loss: 101847676.3200 - concatenate_2_loss: 403.7253 - concatenate_3_loss: 6.3525e-04 - concatenate_4_loss: 2.4385e-15 - concatenate_5_loss: 3.7884e-12\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 18s 367ms/step - loss: 96824806.4000 - concatenate_1_loss: 96824614.8800 - concatenate_2_loss: 191.6725 - concatenate_3_loss: 4.4952e-04 - concatenate_4_loss: 1.4736e-15 - concatenate_5_loss: 2.2303e-12\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 18s 368ms/step - loss: 94439252.6400 - concatenate_1_loss: 94438949.9200 - concatenate_2_loss: 302.7117 - concatenate_3_loss: 4.9486e-04 - concatenate_4_loss: 2.8013e-15 - concatenate_5_loss: 4.2731e-12\n",
            "Epoch 1/5\n",
            "50/50 [==============================] - 18s 369ms/step - loss: 111344761.4400 - concatenate_1_loss: 111344628.4800 - concatenate_2_loss: 132.9961 - concatenate_3_loss: 4.2700e-04 - concatenate_4_loss: 4.1213e-15 - concatenate_5_loss: 1.7399e-12\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 18s 367ms/step - loss: 105885494.0000 - concatenate_1_loss: 105885356.0000 - concatenate_2_loss: 138.7902 - concatenate_3_loss: 3.8026e-04 - concatenate_4_loss: 1.4789e-15 - concatenate_5_loss: 1.1384e-12\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 18s 366ms/step - loss: 100241239.5200 - concatenate_1_loss: 100241093.9200 - concatenate_2_loss: 143.5082 - concatenate_3_loss: 3.4027e-04 - concatenate_4_loss: 2.7698e-16 - concatenate_5_loss: 6.1111e-13\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 18s 366ms/step - loss: 94870841.7600 - concatenate_1_loss: 94870687.2000 - concatenate_2_loss: 154.9926 - concatenate_3_loss: 3.0598e-04 - concatenate_4_loss: 7.2451e-18 - concatenate_5_loss: 2.5075e-13\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 18s 365ms/step - loss: 89911281.9200 - concatenate_1_loss: 89911114.2400 - concatenate_2_loss: 167.6526 - concatenate_3_loss: 2.8289e-04 - concatenate_4_loss: 5.8572e-19 - concatenate_5_loss: 1.8115e-13\n",
            "Epoch 1/5\n",
            "50/50 [==============================] - 18s 367ms/step - loss: 107811644.3200 - concatenate_1_loss: 107811486.7200 - concatenate_2_loss: 158.6780 - concatenate_3_loss: 4.6661e-04 - concatenate_4_loss: 1.9352e-22 - concatenate_5_loss: 3.1451e-15\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 18s 369ms/step - loss: 102511238.8400 - concatenate_1_loss: 102511101.0000 - concatenate_2_loss: 137.6167 - concatenate_3_loss: 4.4092e-04 - concatenate_4_loss: 1.6484e-22 - concatenate_5_loss: 2.8545e-15\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 19s 370ms/step - loss: 94715655.8400 - concatenate_1_loss: 94715575.5200 - concatenate_2_loss: 80.5264 - concatenate_3_loss: 3.5167e-04 - concatenate_4_loss: 6.0030e-24 - concatenate_5_loss: 5.2949e-16\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 19s 371ms/step - loss: 89809779.5200 - concatenate_1_loss: 89809697.9200 - concatenate_2_loss: 82.0156 - concatenate_3_loss: 3.2442e-04 - concatenate_4_loss: 0.0000e+00 - concatenate_5_loss: 0.0000e+00\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 19s 375ms/step - loss: 85262475.8000 - concatenate_1_loss: 85262394.8000 - concatenate_2_loss: 79.2422 - concatenate_3_loss: 3.0573e-04 - concatenate_4_loss: 0.0000e+00 - concatenate_5_loss: 0.0000e+00\n",
            "Epoch 1/5\n",
            "50/50 [==============================] - 19s 371ms/step - loss: 66322009.6400 - concatenate_1_loss: 66321877.8400 - concatenate_2_loss: 131.7057 - concatenate_3_loss: 2.2333e-04 - concatenate_4_loss: 1.3572e-18 - concatenate_5_loss: 3.6467e-13\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 18s 369ms/step - loss: 62403586.0800 - concatenate_1_loss: 62403467.5200 - concatenate_2_loss: 117.9620 - concatenate_3_loss: 2.1289e-04 - concatenate_4_loss: 1.2534e-18 - concatenate_5_loss: 3.6584e-13\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 19s 371ms/step - loss: 58150829.7600 - concatenate_1_loss: 58150713.6000 - concatenate_2_loss: 116.6094 - concatenate_3_loss: 2.0913e-04 - concatenate_4_loss: 1.2164e-18 - concatenate_5_loss: 3.6608e-13\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 19s 371ms/step - loss: 56473863.6800 - concatenate_1_loss: 56473775.5200 - concatenate_2_loss: 87.5383 - concatenate_3_loss: 1.8060e-04 - concatenate_4_loss: 1.1817e-18 - concatenate_5_loss: 3.6155e-13\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 19s 371ms/step - loss: 55670449.5200 - concatenate_1_loss: 55670330.4800 - concatenate_2_loss: 119.2795 - concatenate_3_loss: 1.9947e-04 - concatenate_4_loss: 1.0732e-18 - concatenate_5_loss: 3.4503e-13\n",
            "Epoch 1/5\n",
            "50/50 [==============================] - 18s 370ms/step - loss: 53649274.0875 - concatenate_1_loss: 53649103.4425 - concatenate_2_loss: 170.6525 - concatenate_3_loss: 1.6135e-04 - concatenate_4_loss: 1.0915e-19 - concatenate_5_loss: 8.8658e-14\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 18s 366ms/step - loss: 51419955.5200 - concatenate_1_loss: 51419813.8400 - concatenate_2_loss: 141.9197 - concatenate_3_loss: 1.4554e-04 - concatenate_4_loss: 1.7112e-19 - concatenate_5_loss: 1.1172e-13\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 18s 368ms/step - loss: 42699838.2400 - concatenate_1_loss: 42699674.6400 - concatenate_2_loss: 163.7603 - concatenate_3_loss: 1.3459e-04 - concatenate_4_loss: 2.0528e-19 - concatenate_5_loss: 1.2380e-13\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 18s 365ms/step - loss: 47468663.0400 - concatenate_1_loss: 47468500.8000 - concatenate_2_loss: 161.6900 - concatenate_3_loss: 1.3311e-04 - concatenate_4_loss: 2.5312e-19 - concatenate_5_loss: 1.3556e-13\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 18s 367ms/step - loss: 46043020.8200 - concatenate_1_loss: 46042860.7800 - concatenate_2_loss: 160.5699 - concatenate_3_loss: 1.3011e-04 - concatenate_4_loss: 1.9213e-19 - concatenate_5_loss: 1.1190e-13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-cc8f49b630dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0mX1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;31m#print(X1.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0mX2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m   \u001b[0;31m#X3 = np.asarray(X3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \"\"\"\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (224,218,3) into shape (224)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "y7YjTOW2xLlE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}