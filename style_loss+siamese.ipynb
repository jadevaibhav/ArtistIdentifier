{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "style_loss+siamese.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "4XVCI5_G7yaH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,Dropout, Reshape,Concatenate\n",
        "from keras.models import Model, load_model,Sequential\n",
        "model = keras.applications.vgg16.VGG16(include_top=False, weights='imagenet',input_shape = (224,224,3))\n",
        "\n",
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uvytH8bRJVMx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "9eca2410-2e4b-4d10-c646-d88824ff35cc"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KjKMAyuu9MRo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ErgSmTHU8AiS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "40a717be-4d89-4604-c4f2-93dc8ec02ff4"
      },
      "cell_type": "code",
      "source": [
        "#vgg.summary()\n",
        "for layer in model.layers:\n",
        "  if(layer.name in STYLE_LAYERS):\n",
        "    print(layer.name)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "block1_pool\n",
            "block2_pool\n",
            "block3_pool\n",
            "block4_pool\n",
            "block5_pool\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sTgoSdlvJLfP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "layer_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ngZPJogF9kaE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: compute_layer_style_cost\n",
        "\n",
        "def compute_layer_style_cost(a_S, a_G):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    a_S -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image S \n",
        "    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image G\n",
        "    \n",
        "    Returns: \n",
        "    J_style_layer -- tensor representing a scalar value, style cost defined above by equation (2)\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    # Retrieve dimensions from a_G (≈1 line)\n",
        "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
        "    \n",
        "    # Reshape the images to have them of shape (n_C, n_H*n_W) (≈2 lines)\n",
        "    a_S = tf.reshape(tf.transpose(a_S,perm=[0,3,2,1]),[n_C,n_H*n_W])\n",
        "    a_G = tf.reshape(tf.transpose(a_G,perm=[0,3,2,1]),[n_C,n_H*n_W])\n",
        "\n",
        "    # Computing gram_matrices for both images S and G (≈2 lines)\n",
        "    GS = gram_matrix(a_S)\n",
        "    GG = gram_matrix(a_G)\n",
        "    \n",
        "    # Computing the loss (≈1 line)\n",
        "    J_style_layer = tf.reduce_sum(tf.square(tf.subtract(GS,GG)))/(4*(n_C**2)*((n_H*n_W)**2))\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return J_style_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nu-onjMd9khO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: gram_matrix\n",
        "\n",
        "def gram_matrix(A):\n",
        "    \"\"\"\n",
        "    Argument:\n",
        "    A -- matrix of shape (n_C, n_H*n_W)\n",
        "    \n",
        "    Returns:\n",
        "    GA -- Gram matrix of A, of shape (n_C, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ### (≈1 line)\n",
        "    GA = tf.matmul(A,tf.transpose(A))\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return GA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LkHxvCER8DFJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "STYLE_LAYERS = [\n",
        "    'block1_pool', \n",
        "    'block2_pool', \n",
        "    'block3_pool', \n",
        "    'block4_pool',\n",
        "    'block5_pool']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tkIM5Gg8EBPX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.InteractiveSession()\n",
        "sess.run(vgg..input.assign())\n",
        "compute_style_cost(vgg,STYLE_LAYERS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8Pg-9fSzFI9p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def multi_model(model):\n",
        "  \n",
        "  output = []\n",
        "  \n",
        "  for layer_name in STYLE_LAYERS:\n",
        "    \n",
        "    out = model.get_layer(layer_name).output\n",
        "    #print(type(out))\n",
        "    out = Reshape((1,out.shape[1],out.shape[2],out.shape[3]))(out)\n",
        "    #print(out.shape)\n",
        "    output.append(out) \n",
        "  #output = tf.convert_to_tensor(output)\n",
        "  m = Model(inputs= model.input ,outputs=output)\n",
        "  return m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cANch9_NQ2qm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def art_model(in_shape,model):\n",
        "  \n",
        "  mod = multi_model(model)\n",
        "  \n",
        "  in1 = Input(in_shape)\n",
        "  in2 = Input(in_shape)\n",
        "  \n",
        "  a_a = mod(in1)\n",
        "  a_s = mod(in2)\n",
        "  \n",
        "  #print(a_a[0].shape)\n",
        "  out1 = Concatenate(axis = 1)([a_a[0],a_s[0]])\n",
        "  out2 = Concatenate(axis = 1)([a_a[1],a_s[1]])\n",
        "  out3 = Concatenate(axis = 1)([a_a[2],a_s[2]])\n",
        "  out4 = Concatenate(axis = 1)([a_a[3],a_s[3]])\n",
        "  out5 = Concatenate(axis = 1)([a_a[4],a_s[4]])\n",
        "  \n",
        "  print(out1.shape)\n",
        "  m = Model(inputs = [in1,in2],outputs = [out1,out2,out3,out4,out5])\n",
        "  return m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zFXZFEvUTQNc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "def style_loss(y_true, y_pred, alpha = 0.2):\n",
        "    \"\"\"\n",
        "    Implementation of the triplet loss as defined by formula (3)\n",
        "    \n",
        "    Arguments:\n",
        "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
        "    y_pred -- python list containing three objects:\n",
        "            anchor -- the encodings for the anchor images, of shape (None, 128)\n",
        "            positive -- the encodings for the positive images, of shape (None, 128)\n",
        "            negative -- the encodings for the negative images, of shape (None, 128)\n",
        "    \n",
        "    Returns:\n",
        "    loss -- real number, value of the loss\n",
        "    \"\"\"\n",
        "    \n",
        "    #anchor, positive, negative = y_pred[:,0,:], y_pred[:,1,:], y_pred[:,2,:]\n",
        "    \n",
        "    #print(y_pred.shape)\n",
        "    \n",
        "    J_style = compute_layer_style_cost(y_pred[:,0,:,:,:],y_pred[:,1,:,:,:])\n",
        "    \n",
        "    #for i in range(len(STYLE_LAYERS)):\n",
        "      \n",
        "      #cost = compute_layer_style_cost(y_pred[i,0,:,:],y_pred[i,1,:,:])\n",
        "      #J_style += cost\n",
        "   \n",
        "    \n",
        "    ### START CODE HERE ### (≈ 4 lines)\n",
        "    # Step 1: Compute the (encoding) distance between the anchor and the positive\n",
        "    #pos_dist = tf.reduce_sum(tf.square(anchor - positive))\n",
        "    # Step 2: Compute the (encoding) distance between the anchor and the negative\n",
        "    #neg_dist = tf.reduce_sum(tf.square(anchor - negative))\n",
        "    # Step 3: subtract the two previous distances and add alpha.\n",
        "    #basic_loss = pos_dist - neg_dist + alpha\n",
        "    # Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples.\n",
        "    #loss = tf.maximum(basic_loss, 0)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return J_style"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gFIhMPCsS009",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "4972afb5-b1d4-4e29-b02b-945180cd564d"
      },
      "cell_type": "code",
      "source": [
        "m = art_model((224,224,3),model)\n",
        "m.compile(optimizer= 'adam', loss = [style_loss,style_loss,style_loss,style_loss,style_loss] , metrics = None)\n",
        "m.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "(?, 1, 112, 112, 64)\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "(?, 1, 56, 56, 128)\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "(?, 1, 28, 28, 256)\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "(?, 1, 14, 14, 512)\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "(?, 1, 7, 7, 512)\n",
            "(?, 1, 112, 112, 64)\n",
            "(?, 2, 112, 112, 64)\n",
            "(?, 2, 112, 112, 64)\n",
            "(?, 2, 56, 56, 128)\n",
            "(?, 2, 28, 28, 256)\n",
            "(?, 2, 14, 14, 512)\n",
            "(?, 2, 7, 7, 512)\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_3 (Model)                 [(None, 1, Dimension 14714688    input_5[0][0]                    \n",
            "                                                                 input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 2, Dimension( 0           model_3[1][0]                    \n",
            "                                                                 model_3[2][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 2, Dimension( 0           model_3[1][1]                    \n",
            "                                                                 model_3[2][1]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 2, Dimension( 0           model_3[1][2]                    \n",
            "                                                                 model_3[2][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 2, Dimension( 0           model_3[1][3]                    \n",
            "                                                                 model_3[2][3]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 2, Dimension( 0           model_3[1][4]                    \n",
            "                                                                 model_3[2][4]                    \n",
            "==================================================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IPT31NzSyp3G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "to0LsCQYy-ME",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E2dzhAEWzE_4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2qgP48r5zzk6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('drive/nnfl/NNFL')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mdDJ2Ahu0AFG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "fedc4347-96f6-4cef-9625-66e1bb50e93c"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aleksey_Savrasov      Michelangelo\t   siam_resnet.h5\r\n",
            "artist_siamese.ipynb  Pablo_Picasso\t   siam_resnet_with_softmax.h5\r\n",
            "Claude_Monet\t      Paul_Cezanne\t   style_loss+siamese.ipynb\r\n",
            "code\t\t      Pierre_Renoir\t   test.h5\r\n",
            "comparison.ipynb      preprocessing.ipynb  tranfer_resnet.h5\r\n",
            "data.h5\t\t      Rembrandt\t\t   transfer_resnet50.ipynb\r\n",
            "data_x.h5\t      resnet50+dropout.h5  Van_Gogh\r\n",
            "data_x.pickle\t      resnet50.h5\t   Wassily_Kandisky\r\n",
            "Da_Vinci\t      resnet50.ipynb\r\n",
            "Frida_Kahlo\t      Salvador_Dali\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OkkWgyLMTq41",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2206
        },
        "outputId": "67d0917f-3c20-4b13-94d6-190bd3b31c58"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "path = os.listdir('.')\n",
        "path.sort(key=str)\n",
        "fold = path[:12]\n",
        "#print(fold)\n",
        "\n",
        "for j in range(100):\n",
        "  X1 = []\n",
        "  X2 = []\n",
        "  #X3 = []\n",
        "  for i in range(50):\n",
        "      a = np.random.randint(0,len(fold))\n",
        "      fold1 = os.listdir(fold[a])\n",
        "      fold1.sort(key=str.lower)\n",
        "      #fold2 = os.listdir(fold[b])\n",
        "      #fold2.sort(key=str.lower)\n",
        "      #print(len(fold1))\n",
        "      c,d = random.sample(range(0,len(fold1[:-1])),2)\n",
        "      #e = np.random.randint(0,len(fold2[:-1]))\n",
        "      #print(c==d)\n",
        "      img1 = np.asarray(cv2.imread(fold[a]+'/'+fold1[c],1))\n",
        "      ran = np.random.randint(0,100)\n",
        "      img1 = img1[ran:ran+224,ran:ran+224] \n",
        "      img2 = np.asarray(cv2.imread(fold[a]+'/'+fold1[d],1))\n",
        "      ran = np.random.randint(0,100)\n",
        "      img2 = img2[ran:ran+224,ran:ran+224]\n",
        "      #img3 = np.asarray(cv2.imread(fold[b]+'/'+fold2[e],1))\n",
        "      #ran = np.random.randint(0,100)\n",
        "      #img3 = img3[ran:ran+224,ran:ran+224]\n",
        "      #print(img1.shape,img2.shape,img3.shape)\n",
        "      #print(img1.all() == img2.all())\n",
        "      if(len(img1.shape) == 3 and len(img2.shape) == 3):\n",
        "        X1.append(img1)\n",
        "        X2.append(img2)  \n",
        "        #X3.append(img3)\n",
        "        \n",
        "  X1 = np.asarray(X1)\n",
        "  #print(X1.shape)\n",
        "  X2 = np.asarray(X2)\n",
        "  #X3 = np.asarray(X3)\n",
        "  \n",
        "  y1 = np.zeros((50,2, 112, 112, 64))\n",
        "  y2 = np.zeros((50,2, 56, 56, 128))\n",
        "  y3 = np.zeros((50,2, 28, 28, 256))\n",
        "  y4 = np.zeros((50,2, 14, 14, 512))\n",
        "  y5 = np.zeros((50,2, 7, 7, 512))\n",
        "  \n",
        "  y = [y1,y2,y3,y4,y5]\n",
        "  #print(y.shape)\n",
        "  m.fit([X1,X2],y,epochs=5,batch_size=8)\n",
        "  m.save('siam+style_vgg_art_model.h5')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-6e1b97563daf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;31m#print(y.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m   \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m   \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'siam+style_vgg_art_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 6422528 values, but the requested shape has 802816\n\t [[Node: loss/concatenate_6_loss/Reshape_1 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _class=[\"loc:@training/Adam/gradients/loss/concatenate_6_loss/Reshape_1_grad/Reshape\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](loss/concatenate_6_loss/transpose_1, loss/concatenate_6_loss/Reshape/shape)]]\n\nCaused by op u'loss/concatenate_6_loss/Reshape_1', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-02c26cc908fb>\", line 2, in <module>\n    m.compile(optimizer= 'adam', loss = [style_loss,style_loss,style_loss,style_loss,style_loss] , metrics = None)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/training.py\", line 830, in compile\n    sample_weight, mask)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/training.py\", line 429, in weighted\n    score_array = fn(y_true, y_pred)\n  File \"<ipython-input-12-1d7e9b7d74a4>\", line 21, in style_loss\n    J_style = compute_layer_style_cost(y_pred[:,0,:,:,:],y_pred[:,1,:,:,:])\n  File \"<ipython-input-7-dfc99233bd25>\", line 18, in compute_layer_style_cost\n    a_G = tf.reshape(tf.transpose(a_G,perm=[0,3,2,1]),[n_C,n_H*n_W])\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 6199, in reshape\n    \"Reshape\", tensor=tensor, shape=shape, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Input to reshape is a tensor with 6422528 values, but the requested shape has 802816\n\t [[Node: loss/concatenate_6_loss/Reshape_1 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _class=[\"loc:@training/Adam/gradients/loss/concatenate_6_loss/Reshape_1_grad/Reshape\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](loss/concatenate_6_loss/transpose_1, loss/concatenate_6_loss/Reshape/shape)]]\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "2vt5Wtr9ylvU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}