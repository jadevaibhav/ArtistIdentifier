{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\max2x97\\anaconda3\\lib\\site-packages\n",
      "Requirement already satisfied: pyyaml in c:\\users\\max2x97\\anaconda3\\lib\\site-packages (from keras)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\max2x97\\anaconda3\\lib\\site-packages (from keras)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\max2x97\\anaconda3\\lib\\site-packages (from keras)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\max2x97\\anaconda3\\lib\\site-packages (from keras)\n",
      "Collecting tqdm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Max2x97\\Anaconda3\\lib\\site-packages\\pip\\basecommand.py\", line 215, in main\n",
      "    status = self.run(options, args)\n",
      "  File \"C:\\Users\\Max2x97\\Anaconda3\\lib\\site-packages\\pip\\commands\\install.py\", line 335, in run\n",
      "    wb.build(autobuilding=True)\n",
      "  File \"C:\\Users\\Max2x97\\Anaconda3\\lib\\site-packages\\pip\\wheel.py\", line 749, in build\n",
      "    self.requirement_set.prepare_files(self.finder)\n",
      "  File \"C:\\Users\\Max2x97\\Anaconda3\\lib\\site-packages\\pip\\req\\req_set.py\", line 380, in prepare_files\n",
      "    ignore_dependencies=self.ignore_dependencies))\n",
      "  File \"C:\\Users\\Max2x97\\Anaconda3\\lib\\site-packages\\pip\\req\\req_set.py\", line 554, in _prepare_file\n",
      "    require_hashes\n",
      "  File \"C:\\Users\\Max2x97\\Anaconda3\\lib\\site-packages\\pip\\req\\req_install.py\", line 278, in populate_link\n",
      "    self.link = finder.find_requirement(self, upgrade)\n",
      "  File \"C:\\Users\\Max2x97\\Anaconda3\\lib\\site-packages\\pip\\index.py\", line 465, in find_requirement\n",
      "    all_candidates = self.find_all_candidates(req.name)\n",
      "  File \"C:\\Users\\Max2x97\\Anaconda3\\lib\\site-packages\\pip\\index.py\", line 423, in find_all_candidates\n",
      "    for page in self._get_pages(url_locations, project_name):\n",
      "  File \"C:\\Users\\Max2x97\\Anaconda3\\lib\\site-packages\\pip\\index.py\", line 568, in _get_pages\n",
      "    page = self._get_page(location)\n",
      "  File \"C:\\Users\\Max2x97\\Anaconda3\\lib\\site-packages\\pip\\index.py\", line 683, in _get_page\n",
      "    return HTMLPage.get_page(link, session=self.session)\n",
      "  File \"C:\\Users\\Max2x97\\Anaconda3\\lib\\site-packages\\pip\\index.py\", line 811, in get_page\n",
      "    inst = cls(resp.content, resp.url, resp.headers)\n",
      "  File \"C:\\Users\\Max2x97\\Anaconda3\\lib\\site-packages\\pip\\index.py\", line 731, in __init__\n",
      "    namespaceHTMLElements=False,\n",
      "TypeError: parse() got an unexpected keyword argument 'transport_encoding'\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.initializers import glorot_normal\n",
    "#import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "#from kt_utils import *\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2997, 224, 224, 3)\n",
      "(2997, 12)\n",
      "(299, 224, 224, 3) (2698, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "pickle_off = open(\"dataX_final.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_off)\n",
    "print(X.shape)\n",
    "pickle_on = open(\"dataY_final.pickle\",\"rb\")\n",
    "Y = pickle.load(pickle_on)\n",
    "print(Y.shape)\n",
    "p = np.random.permutation(X.shape[0])\n",
    "X = X[p]\n",
    "Y = Y[p]\n",
    "X_test_orig = X[2698:]\n",
    "X_train_orig = X[:2698]\n",
    "Y_test_orig = Y[2698:]\n",
    "Y_train_orig = Y[:2698]\n",
    "print(X_test_orig.shape, X_train_orig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "number of training examples = 2698\n",
      "number of test examples = 299\n",
      "X_train shape: (2698, 224, 224, 3)\n",
      "Y_train shape: (2698, 12)\n",
      "X_test shape: (299, 224, 224, 3)\n",
      "Y_test shape: (299, 12)\n"
     ]
    }
   ],
   "source": [
    "#X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset_new()\n",
    "X_train = X_train_orig\n",
    "X_test = X_test_orig\n",
    "# Normalize image vectors\n",
    "#X_train = X_train_orig/255.\n",
    "#X_test = X_test_orig/255.\n",
    "x = 0\n",
    "for i in X_train:\n",
    "    i = i/255\n",
    "    x +=1\n",
    "    if x%100 == 0:\n",
    "        print(x)\n",
    "for i in X_test:\n",
    "    i = i/255\n",
    "\n",
    "Y_train = Y_train_orig\n",
    "Y_test = Y_test_orig\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def base_model(input_shape,classes = 12):\n",
    "    \"\"\"Implementation of the BaseModel.\n",
    "       Arguments: input_shape -- shape of the images of the dataset\n",
    "       Returns: model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    #padding of 1\n",
    "    X = ZeroPadding2D(padding=(1, 1))\n",
    "    \n",
    "    # conv layer no padding 3x3  32 filters stride=1\n",
    "    X = Conv2D(32,(3,3),strides=(2,2),name='conv0')(X_input)\n",
    "    X = BatchNormalization(axis = 3, name='bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    #pooling layer(max 2x2 stride 2)\n",
    "    X = MaxPooling2D((2,2),name='maxpool0')(X)\n",
    "    \n",
    "    #padding of 1\n",
    "    X = ZeroPadding2D(padding = (1,1))\n",
    "    \n",
    "    # conv layer no padding 3x3  32 filters stride=1\n",
    "    X = Conv2D(32,(3,3),strides=(2,2),name='conv1')(X_input)\n",
    "    X = BatchNormalization(axis = 3, name='bn1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    #pooling layer(max 2x2 stride 2)\n",
    "    X = MaxPooling2D((2,2),name='maxpool1')(X)\n",
    "    \n",
    "    #flatten()\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(228,activation='relu',activity_regularizer= regularizers.l2(0.01) ,name='fc1', kernel_initializer = glorot_normal(seed=None))(X)\n",
    "    X = Dense(classes,activation='softmax',activity_regularizer= regularizers.l2(0.01) ,name='fc2')(X)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X, name='base_model')\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bsm = base_model((224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bsm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2698/2698 [==============================] - 153s 57ms/step - loss: 4.2753 - acc: 0.1186\n",
      "Epoch 2/20\n",
      "2698/2698 [==============================] - 148s 55ms/step - loss: 2.5199 - acc: 0.1197\n",
      "Epoch 3/20\n",
      "2698/2698 [==============================] - 174s 64ms/step - loss: 2.5093 - acc: 0.1197\n",
      "Epoch 4/20\n",
      "2698/2698 [==============================] - 182s 67ms/step - loss: 2.5002 - acc: 0.1197\n",
      "Epoch 5/20\n",
      "2698/2698 [==============================] - 184s 68ms/step - loss: 2.4922 - acc: 0.1197\n",
      "Epoch 6/20\n",
      "2698/2698 [==============================] - 177s 66ms/step - loss: 2.4852 - acc: 0.1201\n",
      "Epoch 7/20\n",
      "2698/2698 [==============================] - 183s 68ms/step - loss: 2.4792 - acc: 0.1223\n",
      "Epoch 8/20\n",
      "2698/2698 [==============================] - 161s 60ms/step - loss: 2.4738 - acc: 0.1223\n",
      "Epoch 9/20\n",
      "2698/2698 [==============================] - 158s 59ms/step - loss: 2.4692 - acc: 0.1223\n",
      "Epoch 10/20\n",
      "2698/2698 [==============================] - 147s 55ms/step - loss: 2.4651 - acc: 0.1223\n",
      "Epoch 11/20\n",
      "2698/2698 [==============================] - 137s 51ms/step - loss: 2.4617 - acc: 0.1223\n",
      "Epoch 12/20\n",
      "2698/2698 [==============================] - 169s 63ms/step - loss: 2.4584 - acc: 0.1223\n",
      "Epoch 13/20\n",
      "2698/2698 [==============================] - 176s 65ms/step - loss: 2.4556 - acc: 0.1223\n",
      "Epoch 14/20\n",
      "2698/2698 [==============================] - 192s 71ms/step - loss: 2.4532 - acc: 0.1223\n",
      "Epoch 15/20\n",
      "2698/2698 [==============================] - 165s 61ms/step - loss: 2.4510 - acc: 0.1223\n",
      "Epoch 16/20\n",
      "2698/2698 [==============================] - 157s 58ms/step - loss: 2.4492 - acc: 0.1223\n",
      "Epoch 17/20\n",
      "2698/2698 [==============================] - 157s 58ms/step - loss: 2.4475 - acc: 0.1223\n",
      "Epoch 18/20\n",
      "2698/2698 [==============================] - 161s 60ms/step - loss: 2.4461 - acc: 0.1223\n",
      "Epoch 19/20\n",
      "2698/2698 [==============================] - 162s 60ms/step - loss: 2.4448 - acc: 0.1223\n",
      "Epoch 20/20\n",
      "2698/2698 [==============================] - 153s 57ms/step - loss: 2.4437 - acc: 0.1223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1df01d4cb00>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsm.fit(x=X_train,y=Y_train,epochs=20,batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bsm.save(\"my_model_RELU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bsm.evalulate(x=X_test,y=Y_test, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, svm, metrics\n",
    "classifier = svm.SVC(gamma=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(406124544,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)\n",
    "twoX_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150528,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twoX_train =[]\n",
    "twoY_train =[]\n",
    "for i in X_train:\n",
    "    twoX_train.append(i.flatten())\n",
    "for i in Y_train:\n",
    "    twoY_train.append(i.flatten())\n",
    "    \n",
    "(twoX_train[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.fit(twoX_train,twoY_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
